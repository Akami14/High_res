{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":23942,"sourceType":"datasetVersion","datasetId":17839},{"sourceId":4328365,"sourceType":"datasetVersion","datasetId":2548969}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## II. Imports and globals","metadata":{}},{"cell_type":"code","source":"!pip install -U tensorflow==2.11\n!pip install -U keras==2.11","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:19:32.742091Z","iopub.execute_input":"2024-12-03T15:19:32.742634Z","iopub.status.idle":"2024-12-03T15:20:48.962529Z","shell.execute_reply.started":"2024-12-03T15:19:32.742576Z","shell.execute_reply":"2024-12-03T15:20:48.961499Z"}},"outputs":[{"name":"stdout","text":"Collecting tensorflow==2.11\n  Downloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.11) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.11) (1.6.3)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.11) (24.3.25)\nCollecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.11)\n  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.11) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.11) (1.62.2)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.11) (3.11.0)\nCollecting keras<2.12,>=2.11.0 (from tensorflow==2.11)\n  Downloading keras-2.11.0-py2.py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.11) (18.1.1)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.11) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.11) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.11) (21.3)\nCollecting protobuf<3.20,>=3.9.2 (from tensorflow==2.11)\n  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.11) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.11) (1.16.0)\nCollecting tensorboard<2.12,>=2.11 (from tensorflow==2.11)\n  Downloading tensorboard-2.11.2-py3-none-any.whl.metadata (1.9 kB)\nCollecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow==2.11)\n  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.11) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.11) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.11) (1.16.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.11) (0.37.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.11) (0.43.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (2.30.0)\nCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow==2.11)\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (3.6)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (2.32.3)\nCollecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11)\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\nCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11)\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (3.1.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.11) (3.1.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (0.4.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (2.0.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (2024.6.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (2.1.5)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (0.6.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (3.2.2)\nDownloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\nDownloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\nDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, tensorflow-estimator, tensorboard-data-server, protobuf, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.15.0\n    Uninstalling tensorflow-estimator-2.15.0:\n      Successfully uninstalled tensorflow-estimator-2.15.0\n  Attempting uninstall: tensorboard-data-server\n    Found existing installation: tensorboard-data-server 0.7.2\n    Uninstalling tensorboard-data-server-0.7.2:\n      Successfully uninstalled tensorboard-data-server-0.7.2\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: keras\n    Found existing installation: keras 3.3.3\n    Uninstalling keras-3.3.3:\n      Successfully uninstalled keras-3.3.3\n  Attempting uninstall: gast\n    Found existing installation: gast 0.5.4\n    Uninstalling gast-0.5.4:\n      Successfully uninstalled gast-0.5.4\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.0\n    Uninstalling google-auth-oauthlib-1.2.0:\n      Successfully uninstalled google-auth-oauthlib-1.2.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.16.2\n    Uninstalling tensorboard-2.16.2:\n      Successfully uninstalled tensorboard-2.16.2\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.16.1\n    Uninstalling tensorflow-2.16.1:\n      Successfully uninstalled tensorflow-2.16.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.1.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 17.0.0 which is incompatible.\ngcsfs 2024.9.0.post1 requires fsspec==2024.9.0, but you have fsspec 2024.6.0 which is incompatible.\ngoogle-ai-generativelanguage 0.6.10 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-language 2.15.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-spanner 3.47.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-videointelligence 2.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nonnx 1.17.0 requires protobuf>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ntensorboardx 2.6.2.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-datasets 4.9.6 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-decision-forests 1.9.1 requires tensorflow~=2.16.1, but you have tensorflow 2.11.0 which is incompatible.\ntensorflow-serving-api 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-serving-api 2.16.1 requires tensorflow<3,>=2.16.1, but you have tensorflow 2.11.0 which is incompatible.\ntensorflow-text 2.16.1 requires tensorflow<2.17,>=2.16.1; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.11.0 which is incompatible.\ntf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.11.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-0.4.6 keras-2.11.0 protobuf-3.19.6 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0\nRequirement already satisfied: keras==2.11 in /opt/conda/lib/python3.10/site-packages (2.11.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport glob\nimport os\n\nfrom keras import Input\n\nfrom keras.applications import VGG19, EfficientNetB1, EfficientNetB5, Xception, MobileNetV3Large, ConvNeXtBase \n\n\nfrom keras.callbacks import TensorBoard\nfrom keras.layers import BatchNormalization, Activation, LeakyReLU, Add, Dense\nfrom keras.layers import Conv2D, UpSampling2D\nfrom keras.models import Model\nfrom keras.optimizers import Adam\n\n\nimport random\nfrom numpy import asarray\nfrom itertools import repeat\n\nimport imageio\nfrom imageio import imread\nfrom PIL import Image\nfrom skimage.transform import resize as imresize\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"Tensorflow version \" + tf.__version__)\nprint(\"Keras version \" + tf.keras.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:20:48.964460Z","iopub.execute_input":"2024-12-03T15:20:48.964755Z","iopub.status.idle":"2024-12-03T15:20:53.398483Z","shell.execute_reply.started":"2024-12-03T15:20:48.964726Z","shell.execute_reply":"2024-12-03T15:20:53.397438Z"}},"outputs":[{"name":"stdout","text":"Tensorflow version 2.11.0\nKeras version 2.11.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# data path\n\n\nepochs = 5001\n\n# batch size equals to 8 (due to RAM limits)\nbatch_size = 8\n\n# define the shape of low resolution image (LR) \nlow_resolution_shape =  (797, 1200, 3) #(64, 64, 3)\n\n# define the shape of high resolution image (HR) \nhigh_resolution_shape = (797, 1200, 3) #(256, 256, 3)\n\n# optimizer for discriminator, generator \ncommon_optimizer = Adam(0.0002, 0.5)\n\n# use seed for reproducible results\nSEED = 96\ntf.random.set_seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:24:56.455387Z","iopub.execute_input":"2024-12-03T15:24:56.456044Z","iopub.status.idle":"2024-12-03T15:24:56.461965Z","shell.execute_reply.started":"2024-12-03T15:24:56.456013Z","shell.execute_reply":"2024-12-03T15:24:56.461127Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## III. Data\n\nLoad data, process data, EDA","metadata":{}},{"cell_type":"code","source":"\n\nlow = glob.glob('/kaggle/input/image-super-resolution-from-unsplash/Image Super Resolution - Unsplash/high res/*')\nhigh = glob.glob('/kaggle/input/image-super-resolution-from-unsplash/Image Super Resolution - Unsplash/high res/*')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:25:09.360376Z","iopub.execute_input":"2024-12-03T15:25:09.361264Z","iopub.status.idle":"2024-12-03T15:25:09.396005Z","shell.execute_reply.started":"2024-12-03T15:25:09.361228Z","shell.execute_reply":"2024-12-03T15:25:09.395376Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\ndef find_img_dims(image_list):\n    \n    size_1 = [] \n    size_2 = []\n    for i in range(len(image_list)):\n        im = Image.open(image_list[i])\n        size_1.append((im.size[0]))\n        size_2.append((im.size[1]))\n        #print(im.size)\n    max_1 = np.max(size_1)\n    max_2 = np.max(size_2)\n    min_1 = np.min(size_1)\n    min_2 = np.min(size_2)\n    \n    return (max_1, max_2), (min_1, min_2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:25:10.486126Z","iopub.execute_input":"2024-12-03T15:25:10.486756Z","iopub.status.idle":"2024-12-03T15:25:10.492308Z","shell.execute_reply.started":"2024-12-03T15:25:10.486723Z","shell.execute_reply":"2024-12-03T15:25:10.491385Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"find_img_dims(low)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:25:12.491824Z","iopub.execute_input":"2024-12-03T15:25:12.492504Z","iopub.status.idle":"2024-12-03T15:25:19.456336Z","shell.execute_reply.started":"2024-12-03T15:25:12.492468Z","shell.execute_reply":"2024-12-03T15:25:19.455240Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"((1200, 800), (1196, 797))"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"find_img_dims(high)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:25:19.457964Z","iopub.execute_input":"2024-12-03T15:25:19.458281Z","iopub.status.idle":"2024-12-03T15:25:20.779911Z","shell.execute_reply.started":"2024-12-03T15:25:19.458253Z","shell.execute_reply":"2024-12-03T15:25:20.779071Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"((1200, 800), (1196, 797))"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"len(low), len(high)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:25:20.780997Z","iopub.execute_input":"2024-12-03T15:25:20.781308Z","iopub.status.idle":"2024-12-03T15:25:20.787439Z","shell.execute_reply.started":"2024-12-03T15:25:20.781281Z","shell.execute_reply":"2024-12-03T15:25:20.786493Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(1254, 1254)"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"## IV. Utility functions\n\nQuantitative metrics for image quality  \nLoss functions  \nPlots  \nImage processing: sampling and saving images","metadata":{}},{"cell_type":"markdown","source":"### IV A. Metrics","metadata":{}},{"cell_type":"markdown","source":"#### 1. PSNR - Peak Signal-to-Noise ratio\n\n\nPSNR is the ratio between maximum possible power of signal and power of corrupting noise (Wikipedia). \n\n\n$${ PSNR = 10  \\log_{10}  \\left( {MAX_I^2 \\over MSE} \\right) }$$\n\n$ MAX_I $  -  maximum possible power of a signal of image I  \n$ MSE $  -  mean squared error pixel by pixel ","metadata":{}},{"cell_type":"code","source":"def compute_psnr(original_image, generated_image):\n    \n    original_image = tf.convert_to_tensor(original_image, dtype=tf.float32)\n    generated_image = tf.convert_to_tensor(generated_image, dtype=tf.float32)\n    psnr = tf.image.psnr(original_image, generated_image, max_val=1.0)\n\n    return tf.math.reduce_mean(psnr, axis=None, keepdims=False, name=None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:25:33.005961Z","iopub.execute_input":"2024-12-03T15:25:33.006351Z","iopub.status.idle":"2024-12-03T15:25:33.011480Z","shell.execute_reply.started":"2024-12-03T15:25:33.006317Z","shell.execute_reply":"2024-12-03T15:25:33.010473Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def plot_psnr(psnr):\n    \n    psnr_means = psnr['psnr_quality']\n    plt.figure(figsize=(10,8))\n    plt.plot(psnr_means)    \n    plt.xlabel('Epochs')\n    plt.ylabel('PSNR') \n    plt.title('PSNR')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:25:30.410854Z","iopub.execute_input":"2024-12-03T15:25:30.411274Z","iopub.status.idle":"2024-12-03T15:25:30.416419Z","shell.execute_reply.started":"2024-12-03T15:25:30.411239Z","shell.execute_reply":"2024-12-03T15:25:30.415449Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"#### 2. SSIM - Structural Similarity Index\n\n\nSSIM measures the perceptual difference between two similar images [(see Wikipedia)](https://en.wikipedia.org/wiki/Structural_similarity).\n\n$${ SSIM(x, y) = {(2 \\mu_x \\mu_y + c_1) (2 \\sigma_{xy} + c_2) \\over (\\mu_x^2 + \\mu_y^2 + c_1) ( \\sigma_x^2 + \\sigma_y^2 +c_2)}  }$$\n\n\n$ \\mu_x, \\mu_y$       - average value for image $x, y$    \n$ \\sigma_x, \\sigma_y$ - standard deviation for image $x, y$     \n$ \\sigma_{xy}$        - covariance  of $x$ and $y$      \n$ c_1, c_2 $          - coefficients ","metadata":{}},{"cell_type":"code","source":"def compute_ssim(original_image, generated_image):\n    \n    original_image = tf.convert_to_tensor(original_image, dtype=tf.float32)\n    generated_image = tf.convert_to_tensor(generated_image, dtype=tf.float32)\n    ssim = tf.image.ssim(original_image, generated_image, max_val=1.0, filter_size=11,\n                          filter_sigma=1.5, k1=0.01, k2=0.03)\n\n    return tf.math.reduce_mean(ssim, axis=None, keepdims=False, name=None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:25:36.592074Z","iopub.execute_input":"2024-12-03T15:25:36.592823Z","iopub.status.idle":"2024-12-03T15:25:36.597571Z","shell.execute_reply.started":"2024-12-03T15:25:36.592790Z","shell.execute_reply":"2024-12-03T15:25:36.596652Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def plot_ssim(ssim):\n    \n    ssim_means = ssim['ssim_quality']\n\n    plt.figure(figsize=(10,8))\n    plt.plot(ssim_means)\n    plt.xlabel('Epochs')\n    plt.ylabel('SSIM')\n    plt.title('SSIM')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:25:38.144755Z","iopub.execute_input":"2024-12-03T15:25:38.145088Z","iopub.status.idle":"2024-12-03T15:25:38.149879Z","shell.execute_reply.started":"2024-12-03T15:25:38.145058Z","shell.execute_reply":"2024-12-03T15:25:38.148904Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### IV B. Loss Functions\n\nThe most important contribution of the SRGAN paper was the use of a *perceptual loss* function. \n\n\n**Perceptual Loss**  is a weighted sum of the *content loss* and *adversarial loss*.\n\n\n$${ l^{SR} = l_X^{SR} + 10^{-3}l_{Gen}^{SR}}$$\n\n$l^{SR}$ - perceptual loss   \n$l_X^{SR}$ - content loss   \n$l_{Gen}^{SR}$ - adversarial loss \n\n\n****************************\n\n**1. Content Loss**   \nThe SRGAN replaced the *MSE loss* with a *VGG loss*. Both losses are defined below: \n\n         \n**Pixel-wise MSE loss** is the mean squared error between each pixel in the original HR image and a the corresponding pixel in the generated SR image.\n\n\n**VGG loss** is the euclidean distance between the feature maps of the generated SR image and the original HR  image. The feature maps are the activation layers of the pre-trained  VGG 19 network. \n\n$${ l_{{VGG}/{i,j}}^{SR} = {1 \\over {W_{i,j}H_{i,j}}} \\sum\\limits_{x=1}^{W_{i,j}} \\sum\\limits_{y=1}^{H_{i,j}}  ({\\phi}_{i,j}(I^{HR})_{x,y} - {\\phi}_{i,j} (G_{{\\theta}_G} (I^{LR}))_{x,y})^2}$$\n\n\n$ l_{{VGG}/{i,j}}^{SR} $  -  VGG loss    \n$ {\\phi}_{i,j} $  -   the feature map obtained by the j-th convolution (after activation) before the i-th maxpooling layer within the VGG19 network\n\n\n\n**2. Adversarial Loss**  \nThis is calculated based on probabilities provided by Discriminator.\n\n$${ l_{Gen}^{SR} = \\sum\\limits_{n=1}^{N} - \\log{D_{{\\theta}_D}} (G_{{\\theta}_G} (I^{LR}))}$$\n\n$ l_{Gen}^{SR} $  -  generative loss  \n$ D $  -  discriminator function    \n$ D_{{\\theta}_D} $  -  discriminator function parametrized with $ {\\theta}_D $   \n$ {D_{{\\theta}_D}} (G_{{\\theta}_G} (I^{LR})) $   -  probability that the reconstructed image $ \n$ G_{{\\theta}_G} (I^{LR}) $  is a natural HR image","metadata":{}},{"cell_type":"markdown","source":"#### Plot loss function","metadata":{}},{"cell_type":"code","source":"def plot_loss(losses):\n\n    d_loss = losses['d_history']\n    g_loss = losses['g_history']\n    \n   \n    plt.figure(figsize=(10,8))\n    plt.plot(d_loss, label=\"Discriminator loss\")\n    plt.plot(g_loss, label=\"Generator loss\")\n    \n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title(\"Loss\")    \n    plt.legend()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:25:42.490601Z","iopub.execute_input":"2024-12-03T15:25:42.490983Z","iopub.status.idle":"2024-12-03T15:25:42.496283Z","shell.execute_reply.started":"2024-12-03T15:25:42.490955Z","shell.execute_reply":"2024-12-03T15:25:42.495374Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"### IV C. Sampling, saving images","metadata":{}},{"cell_type":"code","source":"def sample_images(image_list, batch_size, high_resolution_shape, low_resolution_shape):\n    \n    \"\"\"\n    Pre-process a batch of training images\n    \"\"\"\n    \n    # image_list is the list of all images\n    # ransom sample a batch of images\n    images_batch = np.random.choice(image_list, size=batch_size)\n    \n    lr_images = []\n    hr_images = []\n    \n\n    for img in images_batch:\n  \n        img1 = imread(img, as_gray=False, pilmode='RGB')\n        #img1 = imread(img, pilmode='RGB')\n        img1 = img1.astype(np.float32)\n        \n        # change the size     \n        img1_high_resolution = imresize(img1, high_resolution_shape)\n        img1_low_resolution = imresize(img1, low_resolution_shape)\n                \n\n        # do a random horizontal flip\n        if np.random.random() < 0.5:\n            img1_high_resolution = np.fliplr(img1_high_resolution)\n            img1_low_resolution = np.fliplr(img1_low_resolution)\n       \n        hr_images.append(img1_high_resolution)\n        lr_images.append(img1_low_resolution)\n        \n   \n    # convert lists into numpy ndarrays\n    return np.array(hr_images), np.array(lr_images)    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:26:19.180925Z","iopub.execute_input":"2024-12-03T15:26:19.181346Z","iopub.status.idle":"2024-12-03T15:26:19.188397Z","shell.execute_reply.started":"2024-12-03T15:26:19.181312Z","shell.execute_reply":"2024-12-03T15:26:19.187471Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def save_images(original_image, lr_image, sr_image, path):\n    \n    \"\"\"\n    Save LR, HR (original) and generated SR\n    images in one panel \n    \"\"\"\n    \n    fig, ax = plt.subplots(1,3, figsize=(10, 6))\n\n    images = [original_image, lr_image, sr_image]\n    titles = ['HR', 'LR','SR - generated']\n\n    for idx,img in enumerate(images):\n        # (X + 1)/2 to scale back from [-1,1] to [0,1]\n        ax[idx].imshow((img + 1)/2.0, cmap='gray')\n        ax[idx].axis(\"off\")\n    for idx, title in enumerate(titles):    \n        ax[idx].set_title('{}'.format(title))\n        \n    plt.savefig(path)    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:56:43.128105Z","iopub.execute_input":"2024-12-01T09:56:43.128478Z","iopub.status.idle":"2024-12-01T09:56:43.134009Z","shell.execute_reply.started":"2024-12-01T09:56:43.128446Z","shell.execute_reply":"2024-12-01T09:56:43.133173Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## V. SRGAN-VGG19","metadata":{}},{"cell_type":"markdown","source":"The SRGAN has the following code components:\n 1. Generator network\n 2.  Discriminator network\n 3. Feature extractor using the VGG19 network\n 4. Adversarial framework","metadata":{}},{"cell_type":"markdown","source":"### V 1. Generator","metadata":{}},{"cell_type":"markdown","source":"There are 16 residual blocks and 2 upsampling blocks. The generator follows the architecture outlined in [2]. ","metadata":{}},{"cell_type":"code","source":"def residual_block(x, paddings, kernel_size = 3, strides = 1, filters = (64, 64),):\n\n    momentum = 0.8\n    activation = \"relu\"\n\n\n    res = Conv2D( filters=filters[0], kernel_size=kernel_size, strides=strides)(x) #padding=padding\n    res =  tf.pad(res, paddings, mode='REFLECT', constant_values=0, name='mirror')\n    res = Activation(activation=activation)(res)\n    res = BatchNormalization(momentum=momentum)(res)\n\n    res = Conv2D(filters=filters[1], kernel_size=kernel_size, strides=strides)(res)  #padding=padding\n    res =  tf.pad(res, paddings, mode='REFLECT', constant_values=0, name='mirror')\n    res = Activation(activation=activation)(res)\n    res = BatchNormalization(momentum=momentum)(res)\n\n\n    res = Conv2D(filters=filters[1], kernel_size=kernel_size, strides=strides, )(res)  #padding=padding\n    res =  tf.pad(res, paddings, mode='REFLECT', constant_values=0, name='mirror')\n    res = BatchNormalization(momentum=momentum)(res)\n\n\n    res = Conv2D(filters=filters[1]/2, kernel_size=1, strides=strides, )(res)\n    #res.s\n    #x = tf.keras.layers.Cropping2D()\n    res = Add()([res, x])\n\n\n    \n    \n    return res","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:29:35.371539Z","iopub.execute_input":"2024-12-03T15:29:35.372140Z","iopub.status.idle":"2024-12-03T15:29:35.378947Z","shell.execute_reply.started":"2024-12-03T15:29:35.372092Z","shell.execute_reply":"2024-12-03T15:29:35.378041Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def build_generator():\n    \n    # use 16 residual blocks in generator\n    residual_blocks = 16\n    momentum = 0.8\n    paddings_3 = tf.constant([[1,1],[1,1], [1,1],[0,0]])\n    paddings_5 = tf.constant([[2,2],[2,2], [2,2],[0,0]])\n    # input LR dimension: 4x downsample of HR\n    input_shape = (797,  1188, 3)\n    \n    # input for the generator\n    input_layer = Input(input_shape)\n    \n    # pre-residual block: conv layer before residual blocks \n    gen1 = Conv2D(filters=32, kernel_size=3, strides=1, activation='relu')(input_layer)\n    gen1 =  tf.pad(gen1, paddings_3, mode='REFLECT', constant_values=0, name='mirror')\n    \n    # add 16 residual blocks\n    #res = residual_block(gen1)\n    for i in range(2 - 1):\n        res = residual_block(gen1, paddings_3, kernel_size = 3, strides = 1, filters = (32, 64) )\n\n\n    res = residual_block(res, paddings_5, kernel_size = 5, strides = 1, filters = (32, 64))\n    res = residual_block(res, paddings_3, kernel_size = 3, strides = 1, filters = [32, 64])\n\n    for i in range(3 - 1):\n        res = residual_block(res, paddings_5, kernel_size = 5, strides = 1, filters = [32, 64] )\n        #1dconv\n    \n    # post-residual block: conv and batch-norm layer after residual blocks\n    gen2 = Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(res)\n    \n    gen2 = BatchNormalization(momentum=momentum)(gen2)\n    \n    # take the sum of pre-residual block(gen1) and post-residual block(gen2)\n    gen3 = Add()([gen2, gen1])\n    \n    # upsampling\n    gen4 = UpSampling2D(size=2)(gen3)\n    gen4 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen4)\n    gen4 = Activation('relu')(gen4)\n    \n    # upsampling\n    gen5 = UpSampling2D(size=2)(gen4)\n    gen5 = Conv2D(filters=256, kernel_size=5, strides=1, padding='same')(gen5)\n    gen5 = Activation('relu')(gen5)\n    \n    # conv layer at the output\n    gen6 = Conv2D(filters=3, kernel_size=7, strides=1, padding='same')(gen5)\n    output = Activation('tanh')(gen6) #silu\n    \n    # model \n    model = Model(inputs=[input_layer], outputs=[output], name='generator')\n\n    return model\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:29:41.033472Z","iopub.execute_input":"2024-12-03T15:29:41.033805Z","iopub.status.idle":"2024-12-03T15:29:41.042931Z","shell.execute_reply.started":"2024-12-03T15:29:41.033777Z","shell.execute_reply":"2024-12-03T15:29:41.042143Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"\ngenerator = build_generator()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:36:52.703352Z","iopub.execute_input":"2024-12-03T15:36:52.703711Z","iopub.status.idle":"2024-12-03T15:36:53.281660Z","shell.execute_reply.started":"2024-12-03T15:36:52.703679Z","shell.execute_reply":"2024-12-03T15:36:53.280938Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"\ngenerator.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:37:00.590667Z","iopub.execute_input":"2024-12-03T15:37:00.591528Z","iopub.status.idle":"2024-12-03T15:37:00.761507Z","shell.execute_reply.started":"2024-12-03T15:37:00.591494Z","shell.execute_reply":"2024-12-03T15:37:00.760581Z"}},"outputs":[{"name":"stdout","text":"Model: \"generator\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_6 (InputLayer)           [(None, 797, 1188,   0           []                               \n                                3)]                                                               \n                                                                                                  \n conv2d_33 (Conv2D)             (None, 795, 1186, 3  896         ['input_6[0][0]']                \n                                2)                                                                \n                                                                                                  \n tf.compat.v1.pad_16 (TFOpLambd  (None, 797, 1188, 3  0          ['conv2d_33[0][0]']              \n a)                             2)                                                                \n                                                                                                  \n conv2d_34 (Conv2D)             (None, 795, 1186, 3  9248        ['tf.compat.v1.pad_16[0][0]']    \n                                2)                                                                \n                                                                                                  \n tf.compat.v1.pad_17 (TFOpLambd  (None, 797, 1188, 3  0          ['conv2d_34[0][0]']              \n a)                             2)                                                                \n                                                                                                  \n activation_13 (Activation)     (None, 797, 1188, 3  0           ['tf.compat.v1.pad_17[0][0]']    \n                                2)                                                                \n                                                                                                  \n batch_normalization_23 (BatchN  (None, 797, 1188, 3  128        ['activation_13[0][0]']          \n ormalization)                  2)                                                                \n                                                                                                  \n conv2d_35 (Conv2D)             (None, 795, 1186, 6  18496       ['batch_normalization_23[0][0]'] \n                                4)                                                                \n                                                                                                  \n tf.compat.v1.pad_18 (TFOpLambd  (None, 797, 1188, 6  0          ['conv2d_35[0][0]']              \n a)                             4)                                                                \n                                                                                                  \n activation_14 (Activation)     (None, 797, 1188, 6  0           ['tf.compat.v1.pad_18[0][0]']    \n                                4)                                                                \n                                                                                                  \n batch_normalization_24 (BatchN  (None, 797, 1188, 6  256        ['activation_14[0][0]']          \n ormalization)                  4)                                                                \n                                                                                                  \n conv2d_36 (Conv2D)             (None, 795, 1186, 6  36928       ['batch_normalization_24[0][0]'] \n                                4)                                                                \n                                                                                                  \n tf.compat.v1.pad_19 (TFOpLambd  (None, 797, 1188, 6  0          ['conv2d_36[0][0]']              \n a)                             4)                                                                \n                                                                                                  \n batch_normalization_25 (BatchN  (None, 797, 1188, 6  256        ['tf.compat.v1.pad_19[0][0]']    \n ormalization)                  4)                                                                \n                                                                                                  \n conv2d_37 (Conv2D)             (None, 797, 1188, 3  2080        ['batch_normalization_25[0][0]'] \n                                2)                                                                \n                                                                                                  \n add_6 (Add)                    (None, 797, 1188, 3  0           ['conv2d_37[0][0]',              \n                                2)                                'tf.compat.v1.pad_16[0][0]']    \n                                                                                                  \n conv2d_38 (Conv2D)             (None, 793, 1184, 3  25632       ['add_6[0][0]']                  \n                                2)                                                                \n                                                                                                  \n tf.compat.v1.pad_20 (TFOpLambd  (None, 797, 1188, 3  0          ['conv2d_38[0][0]']              \n a)                             2)                                                                \n                                                                                                  \n activation_15 (Activation)     (None, 797, 1188, 3  0           ['tf.compat.v1.pad_20[0][0]']    \n                                2)                                                                \n                                                                                                  \n batch_normalization_26 (BatchN  (None, 797, 1188, 3  128        ['activation_15[0][0]']          \n ormalization)                  2)                                                                \n                                                                                                  \n conv2d_39 (Conv2D)             (None, 793, 1184, 6  51264       ['batch_normalization_26[0][0]'] \n                                4)                                                                \n                                                                                                  \n tf.compat.v1.pad_21 (TFOpLambd  (None, 797, 1188, 6  0          ['conv2d_39[0][0]']              \n a)                             4)                                                                \n                                                                                                  \n activation_16 (Activation)     (None, 797, 1188, 6  0           ['tf.compat.v1.pad_21[0][0]']    \n                                4)                                                                \n                                                                                                  \n batch_normalization_27 (BatchN  (None, 797, 1188, 6  256        ['activation_16[0][0]']          \n ormalization)                  4)                                                                \n                                                                                                  \n conv2d_40 (Conv2D)             (None, 793, 1184, 6  102464      ['batch_normalization_27[0][0]'] \n                                4)                                                                \n                                                                                                  \n tf.compat.v1.pad_22 (TFOpLambd  (None, 797, 1188, 6  0          ['conv2d_40[0][0]']              \n a)                             4)                                                                \n                                                                                                  \n batch_normalization_28 (BatchN  (None, 797, 1188, 6  256        ['tf.compat.v1.pad_22[0][0]']    \n ormalization)                  4)                                                                \n                                                                                                  \n conv2d_41 (Conv2D)             (None, 797, 1188, 3  2080        ['batch_normalization_28[0][0]'] \n                                2)                                                                \n                                                                                                  \n add_7 (Add)                    (None, 797, 1188, 3  0           ['conv2d_41[0][0]',              \n                                2)                                'add_6[0][0]']                  \n                                                                                                  \n conv2d_42 (Conv2D)             (None, 795, 1186, 3  9248        ['add_7[0][0]']                  \n                                2)                                                                \n                                                                                                  \n tf.compat.v1.pad_23 (TFOpLambd  (None, 797, 1188, 3  0          ['conv2d_42[0][0]']              \n a)                             2)                                                                \n                                                                                                  \n activation_17 (Activation)     (None, 797, 1188, 3  0           ['tf.compat.v1.pad_23[0][0]']    \n                                2)                                                                \n                                                                                                  \n batch_normalization_29 (BatchN  (None, 797, 1188, 3  128        ['activation_17[0][0]']          \n ormalization)                  2)                                                                \n                                                                                                  \n conv2d_43 (Conv2D)             (None, 795, 1186, 6  18496       ['batch_normalization_29[0][0]'] \n                                4)                                                                \n                                                                                                  \n tf.compat.v1.pad_24 (TFOpLambd  (None, 797, 1188, 6  0          ['conv2d_43[0][0]']              \n a)                             4)                                                                \n                                                                                                  \n activation_18 (Activation)     (None, 797, 1188, 6  0           ['tf.compat.v1.pad_24[0][0]']    \n                                4)                                                                \n                                                                                                  \n batch_normalization_30 (BatchN  (None, 797, 1188, 6  256        ['activation_18[0][0]']          \n ormalization)                  4)                                                                \n                                                                                                  \n conv2d_44 (Conv2D)             (None, 795, 1186, 6  36928       ['batch_normalization_30[0][0]'] \n                                4)                                                                \n                                                                                                  \n tf.compat.v1.pad_25 (TFOpLambd  (None, 797, 1188, 6  0          ['conv2d_44[0][0]']              \n a)                             4)                                                                \n                                                                                                  \n batch_normalization_31 (BatchN  (None, 797, 1188, 6  256        ['tf.compat.v1.pad_25[0][0]']    \n ormalization)                  4)                                                                \n                                                                                                  \n conv2d_45 (Conv2D)             (None, 797, 1188, 3  2080        ['batch_normalization_31[0][0]'] \n                                2)                                                                \n                                                                                                  \n add_8 (Add)                    (None, 797, 1188, 3  0           ['conv2d_45[0][0]',              \n                                2)                                'add_7[0][0]']                  \n                                                                                                  \n conv2d_46 (Conv2D)             (None, 793, 1184, 3  25632       ['add_8[0][0]']                  \n                                2)                                                                \n                                                                                                  \n tf.compat.v1.pad_26 (TFOpLambd  (None, 797, 1188, 3  0          ['conv2d_46[0][0]']              \n a)                             2)                                                                \n                                                                                                  \n activation_19 (Activation)     (None, 797, 1188, 3  0           ['tf.compat.v1.pad_26[0][0]']    \n                                2)                                                                \n                                                                                                  \n batch_normalization_32 (BatchN  (None, 797, 1188, 3  128        ['activation_19[0][0]']          \n ormalization)                  2)                                                                \n                                                                                                  \n conv2d_47 (Conv2D)             (None, 793, 1184, 6  51264       ['batch_normalization_32[0][0]'] \n                                4)                                                                \n                                                                                                  \n tf.compat.v1.pad_27 (TFOpLambd  (None, 797, 1188, 6  0          ['conv2d_47[0][0]']              \n a)                             4)                                                                \n                                                                                                  \n activation_20 (Activation)     (None, 797, 1188, 6  0           ['tf.compat.v1.pad_27[0][0]']    \n                                4)                                                                \n                                                                                                  \n batch_normalization_33 (BatchN  (None, 797, 1188, 6  256        ['activation_20[0][0]']          \n ormalization)                  4)                                                                \n                                                                                                  \n conv2d_48 (Conv2D)             (None, 793, 1184, 6  102464      ['batch_normalization_33[0][0]'] \n                                4)                                                                \n                                                                                                  \n tf.compat.v1.pad_28 (TFOpLambd  (None, 797, 1188, 6  0          ['conv2d_48[0][0]']              \n a)                             4)                                                                \n                                                                                                  \n batch_normalization_34 (BatchN  (None, 797, 1188, 6  256        ['tf.compat.v1.pad_28[0][0]']    \n ormalization)                  4)                                                                \n                                                                                                  \n conv2d_49 (Conv2D)             (None, 797, 1188, 3  2080        ['batch_normalization_34[0][0]'] \n                                2)                                                                \n                                                                                                  \n add_9 (Add)                    (None, 797, 1188, 3  0           ['conv2d_49[0][0]',              \n                                2)                                'add_8[0][0]']                  \n                                                                                                  \n conv2d_50 (Conv2D)             (None, 793, 1184, 3  25632       ['add_9[0][0]']                  \n                                2)                                                                \n                                                                                                  \n tf.compat.v1.pad_29 (TFOpLambd  (None, 797, 1188, 3  0          ['conv2d_50[0][0]']              \n a)                             2)                                                                \n                                                                                                  \n activation_21 (Activation)     (None, 797, 1188, 3  0           ['tf.compat.v1.pad_29[0][0]']    \n                                2)                                                                \n                                                                                                  \n batch_normalization_35 (BatchN  (None, 797, 1188, 3  128        ['activation_21[0][0]']          \n ormalization)                  2)                                                                \n                                                                                                  \n conv2d_51 (Conv2D)             (None, 793, 1184, 6  51264       ['batch_normalization_35[0][0]'] \n                                4)                                                                \n                                                                                                  \n tf.compat.v1.pad_30 (TFOpLambd  (None, 797, 1188, 6  0          ['conv2d_51[0][0]']              \n a)                             4)                                                                \n                                                                                                  \n activation_22 (Activation)     (None, 797, 1188, 6  0           ['tf.compat.v1.pad_30[0][0]']    \n                                4)                                                                \n                                                                                                  \n batch_normalization_36 (BatchN  (None, 797, 1188, 6  256        ['activation_22[0][0]']          \n ormalization)                  4)                                                                \n                                                                                                  \n conv2d_52 (Conv2D)             (None, 793, 1184, 6  102464      ['batch_normalization_36[0][0]'] \n                                4)                                                                \n                                                                                                  \n tf.compat.v1.pad_31 (TFOpLambd  (None, 797, 1188, 6  0          ['conv2d_52[0][0]']              \n a)                             4)                                                                \n                                                                                                  \n batch_normalization_37 (BatchN  (None, 797, 1188, 6  256        ['tf.compat.v1.pad_31[0][0]']    \n ormalization)                  4)                                                                \n                                                                                                  \n conv2d_53 (Conv2D)             (None, 797, 1188, 3  2080        ['batch_normalization_37[0][0]'] \n                                2)                                                                \n                                                                                                  \n add_10 (Add)                   (None, 797, 1188, 3  0           ['conv2d_53[0][0]',              \n                                2)                                'add_9[0][0]']                  \n                                                                                                  \n conv2d_54 (Conv2D)             (None, 797, 1188, 3  9248        ['add_10[0][0]']                 \n                                2)                                                                \n                                                                                                  \n batch_normalization_38 (BatchN  (None, 797, 1188, 3  128        ['conv2d_54[0][0]']              \n ormalization)                  2)                                                                \n                                                                                                  \n add_11 (Add)                   (None, 797, 1188, 3  0           ['batch_normalization_38[0][0]', \n                                2)                                'tf.compat.v1.pad_16[0][0]']    \n                                                                                                  \n up_sampling2d_2 (UpSampling2D)  (None, 1594, 2376,   0          ['add_11[0][0]']                 \n                                32)                                                               \n                                                                                                  \n conv2d_55 (Conv2D)             (None, 1594, 2376,   73984       ['up_sampling2d_2[0][0]']        \n                                256)                                                              \n                                                                                                  \n activation_23 (Activation)     (None, 1594, 2376,   0           ['conv2d_55[0][0]']              \n                                256)                                                              \n                                                                                                  \n up_sampling2d_3 (UpSampling2D)  (None, 3188, 4752,   0          ['activation_23[0][0]']          \n                                256)                                                              \n                                                                                                  \n conv2d_56 (Conv2D)             (None, 3188, 4752,   1638656     ['up_sampling2d_3[0][0]']        \n                                256)                                                              \n                                                                                                  \n activation_24 (Activation)     (None, 3188, 4752,   0           ['conv2d_56[0][0]']              \n                                256)                                                              \n                                                                                                  \n conv2d_57 (Conv2D)             (None, 3188, 4752,   37635       ['activation_24[0][0]']          \n                                3)                                                                \n                                                                                                  \n activation_25 (Activation)     (None, 3188, 4752,   0           ['conv2d_57[0][0]']              \n                                3)                                                                \n                                                                                                  \n==================================================================================================\nTotal params: 2,441,571\nTrainable params: 2,439,907\nNon-trainable params: 1,664\n__________________________________________________________________________________________________\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"### V 2. Discriminator","metadata":{}},{"cell_type":"code","source":"def build_discriminator():\n    \n    # define hyperparameters\n    leakyrelu_alpha = 0.2\n    momentum = 0.8\n    \n    # the input is the HR shape\n    input_shape = (797,  1188, 3)\n    \n    # input layer for discriminator\n    input_layer = Input(shape=input_shape)\n    \n    # 8 convolutional layers with batch normalization  \n    dis1 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(input_layer)\n    dis1 = LeakyReLU(alpha=leakyrelu_alpha)(dis1)\n\n    dis2 = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(dis1)\n    dis2 = LeakyReLU(alpha=leakyrelu_alpha)(dis2)\n    dis2 = BatchNormalization(momentum=momentum)(dis2)\n\n    dis3 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(dis2)\n    dis3 = LeakyReLU(alpha=leakyrelu_alpha)(dis3)\n    dis3 = BatchNormalization(momentum=momentum)(dis3)\n\n    dis4 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same')(dis3)\n    dis4 = LeakyReLU(alpha=leakyrelu_alpha)(dis4)\n    dis4 = BatchNormalization(momentum=0.8)(dis4)\n\n    dis5 = Conv2D(256, kernel_size=3, strides=1, padding='same')(dis4)\n    dis5 = LeakyReLU(alpha=leakyrelu_alpha)(dis5)\n    dis5 = BatchNormalization(momentum=momentum)(dis5)\n\n    dis6 = Conv2D(filters=256, kernel_size=3, strides=2, padding='same')(dis5)\n    dis6 = LeakyReLU(alpha=leakyrelu_alpha)(dis6)\n    dis6 = BatchNormalization(momentum=momentum)(dis6)\n\n    dis7 = Conv2D(filters=512, kernel_size=3, strides=1, padding='same')(dis6)\n    dis7 = LeakyReLU(alpha=leakyrelu_alpha)(dis7)\n    dis7 = BatchNormalization(momentum=momentum)(dis7)\n\n    dis8 = Conv2D(filters=512, kernel_size=3, strides=2, padding='same')(dis7)\n    dis8 = LeakyReLU(alpha=leakyrelu_alpha)(dis8)\n    dis8 = BatchNormalization(momentum=momentum)(dis8)\n    \n    # fully connected layer \n    dis9 = Dense(units=1024)(dis8)\n    dis9 = LeakyReLU(alpha=0.2)(dis9)\n    \n    # last fully connected layer - for classification \n    output = Dense(units=1, activation='sigmoid')(dis9)   \n    \n    model = Model(inputs=[input_layer], outputs=[output], name='discriminator')\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:38:58.965525Z","iopub.execute_input":"2024-12-03T15:38:58.965880Z","iopub.status.idle":"2024-12-03T15:38:58.976350Z","shell.execute_reply.started":"2024-12-03T15:38:58.965852Z","shell.execute_reply":"2024-12-03T15:38:58.975292Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"discriminator = build_discriminator()\ndiscriminator.trainable = True\ndiscriminator.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:39:01.420086Z","iopub.execute_input":"2024-12-03T15:39:01.420784Z","iopub.status.idle":"2024-12-03T15:39:01.645021Z","shell.execute_reply.started":"2024-12-03T15:39:01.420738Z","shell.execute_reply":"2024-12-03T15:39:01.643947Z"}},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":"### V 3. EFB1 Feature Extractor ","metadata":{}},{"cell_type":"code","source":"\nefb1 = EfficientNetB1(input_shape=(797,  1188, 3), include_top=False, weights='imagenet')\n\nextractor = Model(inputs=efb1.inputs, outputs=efb1.get_layer('block5a_project_conv').output)\n#features = extractor.predict(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:54:06.269239Z","iopub.execute_input":"2024-12-03T15:54:06.269565Z","iopub.status.idle":"2024-12-03T15:54:08.753368Z","shell.execute_reply.started":"2024-12-03T15:54:06.269539Z","shell.execute_reply":"2024-12-03T15:54:08.752657Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"def build_VGG19():\n    \n    input_shape = (797,  1188, 3)\n    efb1.outputs = [efb1.get_layer('').output]\n    input_layer = Input(shape=input_shape)\n    features = efb1(input_layer)\n    model = Model(inputs=[input_layer], outputs=[features])\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:45:50.830473Z","iopub.execute_input":"2024-12-03T15:45:50.831313Z","iopub.status.idle":"2024-12-03T15:45:50.835950Z","shell.execute_reply.started":"2024-12-03T15:45:50.831278Z","shell.execute_reply":"2024-12-03T15:45:50.835021Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"def build_adversarial_model(generator, discriminator, feature_extractor):\n    \n    # input layer for high-resolution images\n    input_high_resolution = Input(shape=high_resolution_shape)\n\n    # input layer for low-resolution images\n    input_low_resolution = Input(shape=low_resolution_shape)\n\n    # generate high-resolution images from low-resolution images\n    generated_high_resolution_images = generator(input_low_resolution)\n\n    # extract feature maps from generated images\n    features = feature_extractor(generated_high_resolution_images)\n    \n    # make a discriminator non-trainable \n    discriminator.trainable = False\n    discriminator.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])\n\n    # discriminator will give us a probability estimation for the generated high-resolution images\n    probs = discriminator(generated_high_resolution_images)\n\n    # create and compile \n    adversarial_model = Model([input_low_resolution, input_high_resolution], [probs, features])\n    adversarial_model.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1e-3, 1], optimizer=common_optimizer)\n    \n    return adversarial_model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:38:20.119443Z","iopub.execute_input":"2024-12-03T15:38:20.119798Z","iopub.status.idle":"2024-12-03T15:38:20.125877Z","shell.execute_reply.started":"2024-12-03T15:38:20.119767Z","shell.execute_reply":"2024-12-03T15:38:20.124922Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"adversarial_model = build_adversarial_model(generator, discriminator, extractor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:54:22.583076Z","iopub.execute_input":"2024-12-03T15:54:22.583463Z","iopub.status.idle":"2024-12-03T15:54:23.383057Z","shell.execute_reply.started":"2024-12-03T15:54:22.583434Z","shell.execute_reply":"2024-12-03T15:54:23.382156Z"}},"outputs":[],"execution_count":71},{"cell_type":"markdown","source":"## VI. Training \n","metadata":{}},{"cell_type":"code","source":"# initialize \n\nlosses = {\"d_history\":[], \"g_history\":[]}\npsnr = {'psnr_quality': []}\nssim = {'ssim_quality': []}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# training loop\n\nfor epoch in range(epochs):\n\n    d_history = []\n    g_history = []\n    \n    image_list = get_train_images(data_path)\n    \n    \"\"\"\n    Train the discriminator network\n    \"\"\"\n    \n    hr_images, lr_images = sample_images(image_list, \n                                         batch_size=batch_size,\n                                         low_resolution_shape=low_resolution_shape,\n                                         high_resolution_shape=high_resolution_shape)\n    \n    \n    # normalize the images\n    hr_images = hr_images / 127.5 - 1.\n    lr_images = lr_images / 127.5 - 1.\n    \n    # generate high-resolution images from low-resolution images\n    generated_high_resolution_images = generator.predict(lr_images)\n    \n    # generate a batch of true and fake labels \n    real_labels = np.ones((batch_size, 16, 16, 1))\n    fake_labels = np.zeros((batch_size, 16, 16, 1))\n    \n \n    d_loss_real = discriminator.train_on_batch(hr_images, real_labels)\n    d_loss_real =  np.mean(d_loss_real)\n    d_loss_fake = discriminator.train_on_batch(generated_high_resolution_images, fake_labels)\n    d_loss_fake =  np.mean(d_loss_fake)\n    \n    # calculate total loss of discriminator as average loss on true and fake labels\n    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n    losses['d_history'].append(d_loss)\n   \n\n    \"\"\"\n        Train the generator network\n    \"\"\"\n      \n    # sample a batch of images    \n    hr_images, lr_images = sample_images(image_list, \n                                         batch_size=batch_size,\n                                         low_resolution_shape=low_resolution_shape,\n                                         high_resolution_shape=high_resolution_shape)\n    \n    \n    # normalize the images\n    hr_images = hr_images / 127.5 - 1.\n    lr_images = lr_images / 127.5 - 1.\n    \n    \n    \n    # extract feature maps for true high-resolution images\n    image_features = fe_model.predict(hr_images)\n\n\n    \n    # train the generator\n    g_loss = adversarial_model.train_on_batch([lr_images, hr_images],\n                                               [real_labels, image_features])\n    \n    losses['g_history'].append(0.5 * (g_loss[1]))\n    \n    \n    \n    # calculate the psnr  \n    ps = compute_psnr(hr_images, generated_high_resolution_images) \n    psnr['psnr_quality'].append(ps)\n            \n    # calculate the ssim \n    ss = compute_ssim(hr_images, generated_high_resolution_images)   \n    ssim['ssim_quality'].append(ss)\n\n    \n  \n    \"\"\"\n        save and print image samples\n    \"\"\"\n    \n    if epoch % 500 == 0:\n        \n        hr_images, lr_images = sample_images(image_list, \n                                             batch_size=batch_size,\n                                             low_resolution_shape=low_resolution_shape,\n                                             high_resolution_shape=high_resolution_shape)\n    \n    \n        # normalize the images\n        hr_images = hr_images / 127.5 - 1.\n        lr_images = lr_images / 127.5 - 1.\n    \n    \n        generated_images = generator.predict_on_batch(lr_images)\n    \n        for index, img in enumerate(generated_images):\n            if index < 3:   # comment this line to display all the images\n                save_images(hr_images[index], lr_images[index], img,\n                            path=\"/kaggle/working/img_{}_{}\".format(epoch, index))  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plots - post training\n\nplot_loss(losses)\nplot_psnr(psnr)\nplot_ssim(ssim)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# save model weights\n\ngenerator.save_weights(\"/kaggle/working/srgan_generator.h5\")\ndiscriminator.save_weights(\"/kaggle/working/srgan_discriminator.h5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## VII. References and further reading\n\n\n<a name=\"ref1\"></a>[1] [Goodfellow et al. 'Generative Adversarial Nets'](https://arxiv.org/pdf/1406.2661.pdf)\n\n<a name=\"ref2\"></a>[2] [Ledig et al. 'Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network'](https://arxiv.org/abs/1609.04802)\n\n<a name=\"ref3\"></a>[3] [Kailash Ahirwar. 'Generative Adversarial Networks Projects'](https://github.com/PacktPublishing/Generative-Adversarial-Networks-Projects)\n\n<a name=\"ref4\"></a>[4] [Saeed Anwar et al. 'A Deep Journey into Super-resolution: A Survey'](https://arxiv.org/pdf/1904.07523.pdf)\n\n<a name=\"ref5\"></a>[5] [Xintao Wang et al. 'ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks'](https://arxiv.org/pdf/1809.00219.pdf)","metadata":{}}]}